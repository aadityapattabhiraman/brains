# brains
A small repo for the projects that are done for the brains

## Chronological List of Key Papers in Deep Learning and Computer Vision and NLP

---

### Currently doing Yolo papers for Object detection

### 1. [LeNet-5 (1998)](https://ieeexplore.ieee.org/document/726791)  
**Authors**: Yann LeCun, LÃ©on Bottou, Yoshua Bengio, Patrick Haffner  
**Goal**: Introduced one of the first convolutional neural networks (CNNs) for digit recognition on the MNIST dataset, laying the foundation for modern CNNs.

### 2. [AlexNet (2012)](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)  
**Authors**: Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton  
**Goal**: Revolutionized image classification with a deep neural network (8 layers), ReLU activations, dropout, and GPU acceleration, winning the 2012 ImageNet competition.

### 3. [Word2Vec (2013)](https://arxiv.org/abs/1301.3781)  
**Authors**: Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, Jeffrey Dean  
**Goal**: Introduced **Word2Vec**, a neural network model for learning word embeddings, significantly improving word representations and enabling various NLP applications like sentiment analysis and machine translation.

### 4. [Seq2Seq (2014)](https://arxiv.org/abs/1409.3215)  
**Authors**: Ilya Sutskever, Oriol Vinyals, Quoc V. Le  
**Goal**: Introduced **Sequence-to-Sequence (Seq2Seq)** models with **LSTMs** for tasks like machine translation, enabling models to translate sentences without relying on hand-crafted features.

### 5. [VGGNet (2014)](https://arxiv.org/abs/1409.1556)  
**Authors**: Karen Simonyan, Andrew Zisserman  
**Goal**: Introduced deeper CNNs with small 3x3 filters, demonstrating that depth improves performance in image classification.

### 6. [GoogLeNet (Inception) (2014)](https://arxiv.org/abs/1409.4842)  
**Authors**: Christian Szegedy, Wei Liu, Yangqing Jia, et al.  
**Goal**: Introduced the **Inception module**, using parallel convolution filters of different sizes and reducing computational complexity with 1x1 convolutions.

### 7. [ResNet (2015)](https://arxiv.org/abs/1512.03385)  
**Authors**: Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun  
**Goal**: Introduced **residual connections** (skip connections) to enable the training of much deeper networks, solving the vanishing gradient problem.

### 8. R-CNN
### 9. YoloV1











